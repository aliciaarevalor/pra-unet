{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Patch Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import from_origin\n",
    "import geopandas as gpd\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(image_path, label_path, shapefile_path, output_dir, train_ratio=0.75, val_ratio=0.2, test_ratio=0.05):\n",
    "    \n",
    "    with rasterio.open(image_path) as src_img:\n",
    "        \n",
    "        with rasterio.open(label_path) as src_lbl:\n",
    "            \n",
    "            grid = gpd.read_file(shapefile_path) #Load the satellite image, load the labels, and then the grid containing the patches. \n",
    "            \n",
    "            train_img_dir = os.path.join(output_dir, 'train/images')\n",
    "            val_img_dir = os.path.join(output_dir, 'validation/images')\n",
    "            test_img_dir = os.path.join(output_dir, 'test/images')\n",
    "\n",
    "            train_lbl_dir = os.path.join(output_dir, 'train/labels')\n",
    "            val_lbl_dir = os.path.join(output_dir, 'validation/labels')\n",
    "            test_lbl_dir = os.path.join(output_dir, 'test/labels')\n",
    "            #Create the train, validation, and test directories if they do not already exist.\n",
    "            \n",
    "            for dir_path in [train_img_dir, val_img_dir, test_img_dir, train_lbl_dir, val_lbl_dir, test_lbl_dir]:\n",
    "                if not os.path.exists(dir_path):\n",
    "                    os.makedirs(dir_path)\n",
    "\n",
    "            \n",
    "            indices = list(grid.index)\n",
    "            random.shuffle(indices)\n",
    "            # Shuffle the patch indices for a random distribution\n",
    "            \n",
    "            num_patches = len(indices)\n",
    "            \n",
    "            #num_train = int(train_ratio * num_patches)\n",
    "            #num_val = int(val_ratio * num_patches)\n",
    "            #num_test = num_patches - num_train - num_val\n",
    "\n",
    "            # Ensure we have at least 1 patch for each split\n",
    "            num_train = max(1, int(train_ratio * num_patches))\n",
    "            num_val = max(1, int(val_ratio * num_patches))\n",
    "            num_test = max(1, num_patches - num_train - num_val)\n",
    "\n",
    "            # Calculate the sizes of the train, validation, and test sets.\n",
    "            \n",
    "            train_indices = indices[:num_train]\n",
    "            val_indices = indices[num_train:num_train + num_val]\n",
    "            test_indices = indices[num_train + num_val:]\n",
    "\n",
    "            \n",
    "            def save_patch_and_label(patch, label, transform, output_img_subdir, output_lbl_subdir, patch_filename):\n",
    "                \n",
    "                patch_img_path = os.path.join(output_img_subdir, patch_filename)\n",
    "                with rasterio.open(\n",
    "                    patch_img_path, 'w',\n",
    "                    driver='GTiff',\n",
    "                    height=224, width=224,\n",
    "                    count=4, dtype=patch.dtype, #Set the count variable according to the number of spectral bands you have.\n",
    "                    crs=src_img.crs, transform=transform\n",
    "                ) as dst_img:\n",
    "                    dst_img.write(patch)\n",
    "                print(f\"Image patch {patch_filename} saved in {output_img_subdir}.\")\n",
    "\n",
    "                \n",
    "                patch_lbl_path = os.path.join(output_lbl_subdir, patch_filename)\n",
    "                with rasterio.open(\n",
    "                    patch_lbl_path, 'w',\n",
    "                    driver='GTiff',\n",
    "                    height=224, width=224,\n",
    "                    count=1, dtype=label.dtype,  # Single channel for labels\n",
    "                    crs=src_lbl.crs, transform=transform\n",
    "                ) as dst_lbl:\n",
    "                    dst_lbl.write(label[0, :, :], 1)  # Correcting the write operation\n",
    "                print(f\"Label patch {patch_filename} saved in {output_lbl_subdir}.\")\n",
    "\n",
    "            \n",
    "            for idx, row in grid.iterrows():\n",
    "                geom = [row['geometry']]\n",
    "                auto_value = row['AUTO']  # Column with unique identifiers\n",
    "\n",
    "                # Extract the patch for the image\n",
    "                patch_img, transform = mask(src_img, geom, crop=True)\n",
    "                patch_lbl, _ = mask(src_lbl, geom, crop=True)\n",
    "\n",
    "                # Check the patch size and resize if necessary (for the image and the label)\n",
    "                height_img, width_img = patch_img.shape[1], patch_img.shape[2]\n",
    "                height_lbl, width_lbl = patch_lbl.shape[1], patch_lbl.shape[2]\n",
    "                \n",
    "                if height_img != 224 or width_img != 224:\n",
    "                    resized_patch_img = np.zeros((4, 224, 224), dtype=patch_img.dtype)\n",
    "                    for i in range(4):\n",
    "                        resized_patch_img[i] = cv2.resize(patch_img[i], (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "                    patch_img = resized_patch_img\n",
    "                \n",
    "                if height_lbl != 224 or width_lbl != 224:\n",
    "                    resized_patch_lbl = cv2.resize(patch_lbl[0], (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "                    patch_lbl = resized_patch_lbl[np.newaxis, :, :]  # Add channel dimension\n",
    "                \n",
    "                # Determine the directory to save the patch\n",
    "                patch_filename = f\"patch_{auto_value}.tif\"\n",
    "                if idx in train_indices:\n",
    "                    save_patch_and_label(patch_img, patch_lbl, transform, train_img_dir, train_lbl_dir, patch_filename)\n",
    "                elif idx in val_indices:\n",
    "                    save_patch_and_label(patch_img, patch_lbl, transform, val_img_dir, val_lbl_dir, patch_filename)\n",
    "                elif idx in test_indices:\n",
    "                    save_patch_and_label(patch_img, patch_lbl, transform, test_img_dir, test_lbl_dir, patch_filename)\n",
    "\n",
    "    print(\"Patch and label extraction completed, and distribution performed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input shapes do not overlap raster.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWindowError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\VICTUS\\anaconda3\\envs\\rsenv\\lib\\site-packages\\rasterio\\mask.py:80\u001b[0m, in \u001b[0;36mraster_geometry_mask\u001b[1;34m(dataset, shapes, all_touched, invert, crop, pad, pad_width)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[43mgeometry_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WindowError:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# If shapes do not overlap raster, raise Exception or UserWarning\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# depending on value of crop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\anaconda3\\envs\\rsenv\\lib\\site-packages\\rasterio\\features.py:467\u001b[0m, in \u001b[0;36mgeometry_window\u001b[1;34m(dataset, shapes, pad_x, pad_y, north_up, rotated, pixel_precision, boundless)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m boundless:\n\u001b[1;32m--> 467\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[43mwindow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraster_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m window\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\anaconda3\\envs\\rsenv\\lib\\site-packages\\rasterio\\windows.py:754\u001b[0m, in \u001b[0;36mWindow.intersection\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the intersection of this window and another\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03mWindow\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\anaconda3\\envs\\rsenv\\lib\\site-packages\\rasterio\\windows.py:113\u001b[0m, in \u001b[0;36miter_args.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Iterable):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\anaconda3\\envs\\rsenv\\lib\\site-packages\\rasterio\\windows.py:216\u001b[0m, in \u001b[0;36mintersection\u001b[1;34m(*windows)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m intersect(windows):\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WindowError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindows do not intersect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    218\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdstack([toranges(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m windows])\n",
      "\u001b[1;31mWindowError\u001b[0m: windows do not intersect",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m shapefile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/input/grid.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/patch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mextract_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapefile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 76\u001b[0m, in \u001b[0;36mextract_patches\u001b[1;34m(image_path, label_path, shapefile_path, output_dir, train_ratio, val_ratio, test_ratio)\u001b[0m\n\u001b[0;32m     73\u001b[0m auto_value \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUTO\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Column with unique identifiers\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Extract the patch for the image\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m patch_img, transform \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m patch_lbl, _ \u001b[38;5;241m=\u001b[39m mask(src_lbl, geom, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Check the patch size and resize if necessary (for the image and the label)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\anaconda3\\envs\\rsenv\\lib\\site-packages\\rasterio\\mask.py:178\u001b[0m, in \u001b[0;36mmask\u001b[1;34m(dataset, shapes, all_touched, invert, nodata, filled, crop, pad, pad_width, indexes)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m         nodata \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 178\u001b[0m shape_mask, transform, window \u001b[38;5;241m=\u001b[39m \u001b[43mraster_geometry_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_touched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_touched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     out_shape \u001b[38;5;241m=\u001b[39m (dataset\u001b[38;5;241m.\u001b[39mcount, ) \u001b[38;5;241m+\u001b[39m shape_mask\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\VICTUS\\anaconda3\\envs\\rsenv\\lib\\site-packages\\rasterio\\mask.py:86\u001b[0m, in \u001b[0;36mraster_geometry_mask\u001b[1;34m(dataset, shapes, all_touched, invert, crop, pad, pad_width)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WindowError:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# If shapes do not overlap raster, raise Exception or UserWarning\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# depending on value of crop\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m crop:\n\u001b[1;32m---> 86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput shapes do not overlap raster.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshapes are outside bounds of raster. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAre they in different coordinate reference systems?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Input shapes do not overlap raster."
     ]
    }
   ],
   "source": [
    "image_path = \"../data/input/image_s2_2.tif\"\n",
    "label_path = \"../data/input/label2.tif\"\n",
    "shapefile_path = \"../data/input/grid.shp\"\n",
    "output_dir = \"../data/patch\"\n",
    "extract_patches(image_path, label_path, shapefile_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Images pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "def normalize_img(img):\n",
    "    return img / np.max(img)\n",
    "\n",
    "# Function to read .tif files and convert them into tensors\n",
    "def load_data(image_dir, mask_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if img_file.endswith('.tif') or img_file.endswith('.tiff'):\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            mask_path = os.path.join(mask_dir, img_file)\n",
    "            \n",
    "            # Read images and masks\n",
    "            img = tiff.imread(img_path).astype(np.float32)\n",
    "            mask = tiff.imread(mask_path).astype(np.uint8)\n",
    "            \n",
    "            img = normalize_img(img)\n",
    "            \n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "    \n",
    "    # Convert the lists into numpy arrays\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    # Convert numpy arrays into tensors\n",
    "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "    masks = tf.convert_to_tensor(masks, dtype=tf.uint8)\n",
    "    \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (918, 224, 224, 4)\n",
      "Shape of training labels: (918, 224, 224)\n",
      "Minimum and maximum values of the training images: 7.288246592906944e-07, 1.0\n",
      "Minimum and maximum values of the training labels: 0, 4\n",
      "Minimum and maximum values of the validation images: 3.3804909094214963e-07, 1.0\n",
      "Minimum and maximum values of the validation labels: 0, 4\n"
     ]
    }
   ],
   "source": [
    "train_image_dir = '../data/patch/train/images'\n",
    "train_mask_dir = '../data/patch/train/labels'\n",
    "val_image_dir = '../data/patch/validation/images/'\n",
    "val_mask_dir = '../data/patch/validation/labels'\n",
    "\n",
    "\n",
    "# Load and transform the training data\n",
    "train_images, train_masks = load_data(train_image_dir, train_mask_dir)\n",
    "val_images, val_masks = load_data(val_image_dir, val_mask_dir)\n",
    "\n",
    "print(f'Shape of training images: {train_images.shape}')\n",
    "print(f'Shape of training labels: {train_masks.shape}')\n",
    "\n",
    "# Check the pixel values of the images\n",
    "print(f'Minimum and maximum values of the training images: {tf.reduce_min(train_images).numpy()}, {tf.reduce_max(train_images).numpy()}')\n",
    "print(f'Minimum and maximum values of the training labels: {tf.reduce_min(train_masks).numpy()}, {tf.reduce_max(train_masks).numpy()}')\n",
    "\n",
    "print(f'Minimum and maximum values of the validation images: {tf.reduce_min(val_images).numpy()}, {tf.reduce_max(val_images).numpy()}')\n",
    "print(f'Minimum and maximum values of the validation labels: {tf.reduce_min(val_masks).numpy()}, {tf.reduce_max(val_masks).numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 : Train of the U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 224, 224, 64  2368        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 224, 224, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 224, 224, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 224, 224, 64  36928       ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 224, 224, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 224, 224, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 64  0           ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 112, 112, 64  0           ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 112, 112, 12  73856       ['dropout[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 112, 112, 12  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 112, 112, 12  0           ['batch_normalization_2[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 112, 112, 12  147584      ['activation_2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 112, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 112, 112, 12  0           ['batch_normalization_3[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 56, 56, 128)  0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 256)  295168      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 256)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 256)  590080      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 56, 56, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 256)  0          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 28, 28, 256)  0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 28, 28, 512)  1180160     ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 28, 28, 512)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 28, 28, 512)  2359808     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 28, 28, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 28, 28, 512)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 512)  0          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 14, 14, 512)  0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 14, 14, 1024  4719616     ['dropout_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 14, 14, 1024  4096       ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 14, 14, 1024  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 14, 14, 1024  9438208     ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 14, 14, 1024  4096       ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 14, 14, 1024  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 28, 28, 1024  0           ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 28, 1536  0           ['activation_7[0][0]',           \n",
      "                                )                                 'up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 28, 28, 512)  7078400     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 28, 28, 512)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 28, 28, 512)  2359808     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 28, 28, 512)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 512)  0          ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 56, 56, 768)  0           ['activation_5[0][0]',           \n",
      "                                                                  'up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 56, 56, 256)  1769728     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 56, 56, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 56, 56, 256)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 56, 56, 256)  590080      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 56, 56, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 56, 56, 256)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 112, 112, 25  0          ['activation_13[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 112, 112, 38  0           ['activation_3[0][0]',           \n",
      "                                4)                                'up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 112, 112, 12  442496      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 112, 112, 12  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 112, 112, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 112, 112, 12  147584      ['activation_14[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 112, 112, 12  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 112, 112, 12  0           ['batch_normalization_15[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 12  0          ['activation_15[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 224, 224, 19  0           ['activation_1[0][0]',           \n",
      "                                2)                                'up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 224, 224, 64  110656      ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 224, 224, 64  256        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 224, 224, 64  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 224, 224, 64  36928       ['activation_16[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 224, 224, 64  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 224, 224, 64  0           ['batch_normalization_17[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 224, 224, 5)  325         ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,403,333\n",
      "Trainable params: 31,391,557\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.5824 - accuracy: 0.8512\n",
      "Epoch 1: val_loss improved from inf to 0.57145, saving model to ..\\saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 1065s 5s/step - loss: 0.5824 - accuracy: 0.8512 - val_loss: 0.5714 - val_accuracy: 0.8615\n",
      "Epoch 2/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.8587\n",
      "Epoch 2: val_loss did not improve from 0.57145\n",
      "230/230 [==============================] - 1028s 4s/step - loss: 0.5139 - accuracy: 0.8587 - val_loss: 0.5968 - val_accuracy: 0.8637\n",
      "Epoch 3/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.8588\n",
      "Epoch 3: val_loss did not improve from 0.57145\n",
      "230/230 [==============================] - 1032s 4s/step - loss: 0.4996 - accuracy: 0.8588 - val_loss: 9.9252 - val_accuracy: 0.8629\n",
      "Epoch 4/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.8599\n",
      "Epoch 4: val_loss did not improve from 0.57145\n",
      "230/230 [==============================] - 1027s 4s/step - loss: 0.4889 - accuracy: 0.8599 - val_loss: 0.9421 - val_accuracy: 0.5970\n",
      "Epoch 5/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.8609\n",
      "Epoch 5: val_loss improved from 0.57145 to 0.54392, saving model to ..\\saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 1036s 5s/step - loss: 0.4829 - accuracy: 0.8609 - val_loss: 0.5439 - val_accuracy: 0.8692\n",
      "Epoch 6/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.8606\n",
      "Epoch 6: val_loss improved from 0.54392 to 0.52291, saving model to ..\\saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 1038s 5s/step - loss: 0.4761 - accuracy: 0.8606 - val_loss: 0.5229 - val_accuracy: 0.8659\n",
      "Epoch 7/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.8607\n",
      "Epoch 7: val_loss improved from 0.52291 to 0.49533, saving model to ..\\saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 1047s 5s/step - loss: 0.4785 - accuracy: 0.8607 - val_loss: 0.4953 - val_accuracy: 0.8682\n",
      "Epoch 8/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.8620\n",
      "Epoch 8: val_loss did not improve from 0.49533\n",
      "230/230 [==============================] - 1032s 4s/step - loss: 0.4657 - accuracy: 0.8620 - val_loss: 0.5587 - val_accuracy: 0.8662\n",
      "Epoch 9/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4714 - accuracy: 0.8606\n",
      "Epoch 9: val_loss improved from 0.49533 to 0.42955, saving model to ..\\saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 1046s 5s/step - loss: 0.4714 - accuracy: 0.8606 - val_loss: 0.4296 - val_accuracy: 0.8691\n",
      "Epoch 10/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.8623\n",
      "Epoch 10: val_loss did not improve from 0.42955\n",
      "230/230 [==============================] - 1026s 4s/step - loss: 0.4638 - accuracy: 0.8623 - val_loss: 0.5603 - val_accuracy: 0.8653\n",
      "Epoch 11/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4646 - accuracy: 0.8618\n",
      "Epoch 11: val_loss did not improve from 0.42955\n",
      "230/230 [==============================] - 1033s 4s/step - loss: 0.4646 - accuracy: 0.8618 - val_loss: 0.5361 - val_accuracy: 0.8610\n",
      "Epoch 12/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.8626\n",
      "Epoch 12: val_loss did not improve from 0.42955\n",
      "230/230 [==============================] - 1021s 4s/step - loss: 0.4618 - accuracy: 0.8626 - val_loss: 0.5450 - val_accuracy: 0.8652\n",
      "Epoch 13/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4619 - accuracy: 0.8614\n",
      "Epoch 13: val_loss did not improve from 0.42955\n",
      "230/230 [==============================] - 1027s 4s/step - loss: 0.4619 - accuracy: 0.8614 - val_loss: 0.6254 - val_accuracy: 0.8603\n",
      "Epoch 14/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4586 - accuracy: 0.8633\n",
      "Epoch 14: val_loss did not improve from 0.42955\n",
      "230/230 [==============================] - 1020s 4s/step - loss: 0.4586 - accuracy: 0.8633 - val_loss: 0.5350 - val_accuracy: 0.8680\n",
      "Epoch 15/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4589 - accuracy: 0.8625\n",
      "Epoch 15: val_loss improved from 0.42955 to 0.42772, saving model to ..\\saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 1045s 5s/step - loss: 0.4589 - accuracy: 0.8625 - val_loss: 0.4277 - val_accuracy: 0.8697\n",
      "Epoch 16/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.8631\n",
      "Epoch 16: val_loss did not improve from 0.42772\n",
      "230/230 [==============================] - 1035s 4s/step - loss: 0.4539 - accuracy: 0.8631 - val_loss: 0.4637 - val_accuracy: 0.8697\n",
      "Epoch 17/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4435 - accuracy: 0.8644\n",
      "Epoch 17: val_loss did not improve from 0.42772\n",
      "230/230 [==============================] - 1029s 4s/step - loss: 0.4435 - accuracy: 0.8644 - val_loss: 0.4393 - val_accuracy: 0.8740\n",
      "Epoch 18/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8627\n",
      "Epoch 18: val_loss did not improve from 0.42772\n",
      "230/230 [==============================] - 1038s 5s/step - loss: 0.4525 - accuracy: 0.8627 - val_loss: 0.4298 - val_accuracy: 0.8722\n",
      "Epoch 19/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.8641\n",
      "Epoch 19: val_loss did not improve from 0.42772\n",
      "230/230 [==============================] - 1027s 4s/step - loss: 0.4474 - accuracy: 0.8641 - val_loss: 0.4496 - val_accuracy: 0.8684\n",
      "Epoch 20/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.8633\n",
      "Epoch 20: val_loss did not improve from 0.42772\n",
      "230/230 [==============================] - 1040s 5s/step - loss: 0.4460 - accuracy: 0.8633 - val_loss: 0.4288 - val_accuracy: 0.8663\n",
      "Epoch 21/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4382 - accuracy: 0.8653\n",
      "Epoch 21: val_loss did not improve from 0.42772\n",
      "230/230 [==============================] - 1030s 4s/step - loss: 0.4382 - accuracy: 0.8653 - val_loss: 0.4584 - val_accuracy: 0.8689\n",
      "Epoch 22/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4488 - accuracy: 0.8640\n",
      "Epoch 22: val_loss did not improve from 0.42772\n",
      "230/230 [==============================] - 1031s 4s/step - loss: 0.4488 - accuracy: 0.8640 - val_loss: 0.4575 - val_accuracy: 0.8699\n",
      "Epoch 23/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8656\n",
      "Epoch 23: val_loss did not improve from 0.42772\n",
      "230/230 [==============================] - 1035s 5s/step - loss: 0.4471 - accuracy: 0.8656 - val_loss: 0.4655 - val_accuracy: 0.8698\n",
      "Epoch 24/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.8658\n",
      "Epoch 24: val_loss improved from 0.42772 to 0.41723, saving model to ..\\saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 1032s 4s/step - loss: 0.4404 - accuracy: 0.8658 - val_loss: 0.4172 - val_accuracy: 0.8761\n",
      "Epoch 25/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.8638\n",
      "Epoch 25: val_loss did not improve from 0.41723\n",
      "230/230 [==============================] - 1028s 4s/step - loss: 0.4404 - accuracy: 0.8638 - val_loss: 0.4932 - val_accuracy: 0.8676\n",
      "Epoch 26/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.8665\n",
      "Epoch 26: val_loss did not improve from 0.41723\n",
      "230/230 [==============================] - 1036s 5s/step - loss: 0.4373 - accuracy: 0.8665 - val_loss: 0.6512 - val_accuracy: 0.7609\n",
      "Epoch 27/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.8643\n",
      "Epoch 27: val_loss did not improve from 0.41723\n",
      "230/230 [==============================] - 1033s 4s/step - loss: 0.4339 - accuracy: 0.8643 - val_loss: 0.4767 - val_accuracy: 0.8675\n",
      "Epoch 28/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4363 - accuracy: 0.8649\n",
      "Epoch 28: val_loss did not improve from 0.41723\n",
      "230/230 [==============================] - 1013s 4s/step - loss: 0.4363 - accuracy: 0.8649 - val_loss: 0.4688 - val_accuracy: 0.8677\n",
      "Epoch 29/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.8674\n",
      "Epoch 29: val_loss did not improve from 0.41723\n",
      "230/230 [==============================] - 1003s 4s/step - loss: 0.4381 - accuracy: 0.8674 - val_loss: 0.4317 - val_accuracy: 0.8757\n",
      "Epoch 30/30\n",
      "230/230 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.8660\n",
      "Epoch 30: val_loss did not improve from 0.41723\n",
      "230/230 [==============================] - 1000s 4s/step - loss: 0.4387 - accuracy: 0.8660 - val_loss: 0.4265 - val_accuracy: 0.8695\n",
      "The best model has been saved in SavedModel format at ../saved_model.\n"
     ]
    }
   ],
   "source": [
    "def unet_advanced(input_shape, num_classes=6):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encodeur\n",
    "    conv1 = Conv2D(64, 3, padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(64, 3, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.5)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(128, 3, padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(256, 3, padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(512, 3, padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(1024, 3, padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    merge6 = Concatenate()([conv4, up6])\n",
    "    conv6 = Conv2D(512, 3, padding='same')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Conv2D(512, 3, padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    merge7 = Concatenate()([conv3, up7])\n",
    "    conv7 = Conv2D(256, 3, padding='same')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Conv2D(256, 3, padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "\n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    merge8 = Concatenate()([conv2, up8])\n",
    "    conv8 = Conv2D(128, 3, padding='same')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    conv8 = Conv2D(128, 3, padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    \n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    merge9 = Concatenate()([conv1, up9])\n",
    "    conv9 = Conv2D(64, 3, padding='same')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "    conv9 = Conv2D(64, 3, padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the parameters\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "num_channels = 4  # Variable to select the number of input channels\n",
    "num_classes = 5   # Here is the number of classes you need to predict +1\n",
    "batch_size = 4   # Reduce the batch size to decrease memory usage\n",
    "\n",
    "# Initialize the U-Net model\n",
    "input_shape = (img_height, img_width, num_channels)\n",
    "model = unet_advanced(input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# Define the callback to save the best epoch\n",
    "saved_model_path = \"../saved_model\"\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=saved_model_path,  # Path to save the best model\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_format=\"tf\",  # Ensure SavedModel format\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the callback\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_masks,\n",
    "    batch_size=batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=(val_images, val_masks),\n",
    "    callbacks=[checkpoint_cb]\n",
    ")\n",
    "\n",
    "print(f\"The best model has been saved in SavedModel format at {saved_model_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell modified from original file due with problems with kernel crashing when plotting accuracy metrics\n",
    "\n",
    "# Create a DataFrame with the metric values\n",
    "metrics = pd.DataFrame({\n",
    "    'Epoch': list(range(1, len(history.history['accuracy']) + 1)),\n",
    "    'Train Accuracy': history.history['accuracy'],\n",
    "    'Validation Accuracy': history.history['val_accuracy'],\n",
    "    'Train Loss': history.history['loss'],\n",
    "    'Validation Loss': history.history['val_loss']\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "metrics.to_excel('../results/metric_values.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 : Displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test image: (1, 224, 224, 4)\n",
      "Shape of test mask: (224, 224)\n",
      "1/1 [==============================] - 1s 598ms/step\n",
      "Predicted mask saved as ../results/prediction/predicted_mask.tif\n"
     ]
    }
   ],
   "source": [
    "# Normalize the image\n",
    "def normalize_img(img):\n",
    "    return img / np.max(img)\n",
    "\n",
    "# Load a test image and keep the geo-referencing information\n",
    "def load_test_image(image_path):\n",
    "    img = tiff.imread(image_path).astype(np.float32)\n",
    "    img = normalize_img(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Read the geo-referencing info (e.g., transform and CRS)\n",
    "    with rasterio.open(image_path) as src:\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        \n",
    "    return img, transform, crs\n",
    "\n",
    "# Load a test label\n",
    "def load_test_mask(mask_path):\n",
    "    mask = tiff.imread(mask_path).astype(np.uint8)\n",
    "    return mask\n",
    "\n",
    "# Paths to the test image and test label\n",
    "test_image_path = '../data/patch/test/images/patch_379.0.tif'  \n",
    "test_mask_path = '../data/patch/test/labels/patch_379.0.tif'\n",
    "\n",
    "# Load the saved model (SavedModel format)\n",
    "saved_model_path = '../saved_model'  # Path to the directory of the SavedModel\n",
    "model = tf.keras.models.load_model(saved_model_path)\n",
    "\n",
    "# Load and prepare the test image and test label\n",
    "test_image, transform, crs = load_test_image(test_image_path)\n",
    "test_mask = load_test_mask(test_mask_path)\n",
    "print(f'Shape of test image: {test_image.shape}')\n",
    "print(f'Shape of test mask: {test_mask.shape}')\n",
    "\n",
    "# Predict the segmentation of the test image\n",
    "prediction = model.predict(test_image)\n",
    "predicted_mask = tf.argmax(prediction, axis=-1)\n",
    "predicted_mask = tf.squeeze(predicted_mask).numpy()\n",
    "\n",
    "# Save the predicted mask with geo-referencing\n",
    "predicted_mask_path = '../results/prediction/predicted_mask.tif'  # Replace with the path where you want to save the predicted mask\n",
    "\n",
    "# Write the predicted mask using rasterio, preserving the geo-referencing\n",
    "with rasterio.open(test_image_path) as src:\n",
    "    meta = src.meta  # Get the metadata (including the transform)\n",
    "    meta.update(driver='GTiff', dtype=rasterio.uint8, count=1)  # Update the metadata to match the predicted mask's data type and single band count\n",
    "    \n",
    "    # Save the predicted mask as a georeferenced TIFF\n",
    "    with rasterio.open(predicted_mask_path, 'w', **meta) as dst:\n",
    "        dst.write(predicted_mask, 1)  # Write the predicted mask as the first band\n",
    "\n",
    "print(f'Predicted mask saved as {predicted_mask_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
